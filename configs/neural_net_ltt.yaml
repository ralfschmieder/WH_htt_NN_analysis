signal: ["sig"]
hidden_layers: [128,128]
dropout_p: 0.3
features: "wh_htt_ltt"
classes: "wh_htt_ltt"
tca: False
tca_order: 2
learning_rate: 0.0001
L2: 0.001
batch_size: 256
early_stopping_patience: 50
early_stopping_value: 0.1
one_hot_parametrization: False
date: "11_07_24_bestHypermodel_allInputs_loose"